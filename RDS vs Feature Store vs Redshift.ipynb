{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e142d8e8",
   "metadata": {},
   "source": [
    "# Performance comparison for AWS RDS vs Redshift vs FeatureStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47d37c",
   "metadata": {},
   "source": [
    "First we will create a simple Pandas dataframe which we will use as a feature repository (Typically we create feature repository after preprocessing and transformation of the source data saved in S3 data lake , but for simplicity sake I will use a pandas dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bbc7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install all required python pacakages sqlalchemy==1.4.49 sqlalchemy-redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0607ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "data = {'Name': ['John', 'Anna', 'Peter', 'Linda'], 'Age': [28, 22, 35, 32]}\n",
    "df = pd.DataFrame(data)\n",
    "#now we have to create recordId and eventTime as 2 additonal features as its a requirement for Feature Store\n",
    "df['eventTime'] = [datetime.utcnow().isoformat() + \"Z\" for _ in range(len(df))]\n",
    "df['recordId'] = [str(uuid.uuid4()) for _ in range(len(df))]  # Unique identifier for each record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b32a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>eventTime</th>\n",
       "      <th>recordId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>28</td>\n",
       "      <td>2023-09-21T13:21:57.251165Z</td>\n",
       "      <td>ad957c5c-5cf9-4921-87cd-3167f77f5b0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anna</td>\n",
       "      <td>22</td>\n",
       "      <td>2023-09-21T13:21:57.251172Z</td>\n",
       "      <td>c99b6b11-6694-465d-99ef-0f454247ca67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peter</td>\n",
       "      <td>35</td>\n",
       "      <td>2023-09-21T13:21:57.251173Z</td>\n",
       "      <td>f30f24bf-f951-4122-99bf-b5d389b896eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linda</td>\n",
       "      <td>32</td>\n",
       "      <td>2023-09-21T13:21:57.251175Z</td>\n",
       "      <td>89d53b95-8093-48d1-8e7e-eb40b22ae388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age                    eventTime  \\\n",
       "0   John   28  2023-09-21T13:21:57.251165Z   \n",
       "1   Anna   22  2023-09-21T13:21:57.251172Z   \n",
       "2  Peter   35  2023-09-21T13:21:57.251173Z   \n",
       "3  Linda   32  2023-09-21T13:21:57.251175Z   \n",
       "\n",
       "                               recordId  \n",
       "0  ad957c5c-5cf9-4921-87cd-3167f77f5b0b  \n",
       "1  c99b6b11-6694-465d-99ef-0f454247ca67  \n",
       "2  f30f24bf-f951-4122-99bf-b5d389b896eb  \n",
       "3  89d53b95-8093-48d1-8e7e-eb40b22ae388  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eda937",
   "metadata": {},
   "source": [
    "Next, we will evaluate the performance of each AWS Service by measuring the time required to insert the feature repository, represented by the dataframe 'df' in our case, into their platform. Subsequently, we will also measure the time it takes to retrieve a record from that dataset. Typically, this retrieved record is then used for real-time ML model inferencing or predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03bb712",
   "metadata": {},
   "source": [
    "# Sagemaker Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb40e9d",
   "metadata": {},
   "source": [
    "First we need to create feature group for feature store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e371c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup, FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# Assuming df is feature repository\n",
    "\n",
    "# Setup\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role_arn = get_execution_role()\n",
    "\n",
    "# Define feature group name\n",
    "feature_group_name = 'feature_repository'\n",
    "bucket_name='Your_S3_bucket_name'\n",
    "\n",
    "# Define feature definitions\n",
    "feature_definitions = [\n",
    "    FeatureDefinition(feature_name=col, feature_type=FeatureTypeEnum.STRING) \n",
    "    if df[col].dtype == 'object' else FeatureDefinition(feature_name=col, feature_type=FeatureTypeEnum.INTEGRAL)\n",
    "    for col in df.columns\n",
    "]\n",
    "\n",
    "# Create FeatureGroup\n",
    "feature_group = FeatureGroup(\n",
    "    name=feature_group_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    feature_definitions=feature_definitions\n",
    ")\n",
    "\n",
    "# Create the feature group\n",
    "feature_group.create(\n",
    "    s3_uri=f's3://{bucket_name}',  # replace with your S3 bucket URI\n",
    "    record_identifier_name='recordId',  # replace with your record identifier feature name\n",
    "    event_time_feature_name='eventTime',  # replace with your event time feature name\n",
    "    role_arn=role_arn,  # use the role ARN you have\n",
    "    enable_online_store=True #For faster retrieval in case of real time inferencing\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Feature Group Created Successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd561bf",
   "metadata": {},
   "source": [
    "Now lets calculate the time taken for data insertion and retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1457275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Store Insert Time: 0.04401803016662598\n",
      "Feature Store Retrieve Time: 0.03712344169616699\n",
      "Total Time: 0.08114147186279297\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# Initialize the SageMaker session and FeatureStore Runtime client\n",
    "sagemaker_session = sagemaker.Session()\n",
    "featurestore_runtime = boto3.client(service_name='sagemaker-featurestore-runtime', region_name=sagemaker_session.boto_region_name)\n",
    "\n",
    "# Your feature group name\n",
    "feature_group_name = 'feature_repository'\n",
    "\n",
    "\n",
    "\n",
    "# Measuring the time for inserting records.\n",
    "start_time = time.time()\n",
    "feature_group.ingest(data_frame=df)\n",
    "feature_store_insert_time = time.time() - start_time\n",
    "print(f'Feature Store Insert Time: {feature_store_insert_time}')\n",
    "\n",
    "# Measuring the time for retrieving records.\n",
    "start_time = time.time()\n",
    "#Lets retrieve the third row from the df dataframe having recordId f30f24bf-f951-4122-99bf-b5d389b896eb\n",
    "response = featurestore_runtime.get_record(FeatureGroupName=feature_group_name, \n",
    "                                               RecordIdentifierValueAsString='f30f24bf-f951-4122-99bf-b5d389b896eb')\n",
    "feature_store_retrieve_time = time.time() - start_time\n",
    "print(f'Feature Store Retrieve Time: {feature_store_retrieve_time}')\n",
    "\n",
    "print(f'Total Time: {feature_store_insert_time + feature_store_retrieve_time}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc221e",
   "metadata": {},
   "source": [
    "# AWS RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da8aeccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert Time: 0.1189734935760498 seconds\n",
      "Fetch Time: 0.039176225662231445 seconds\n",
      "Total Execution Time: 0.15814971923828125 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Database connection details\n",
    "username = 'Your_RDS_Username'\n",
    "password = 'Your_RDS_Password'\n",
    "host = 'Your_RDS_Endpoint'\n",
    "port = '3306'  # default port for MySQL\n",
    "database = 'Your_Database_name'  \n",
    "table_name = 'Your_tablename'  \n",
    "\n",
    "# Create Engine and Session\n",
    "engine_url = f'mysql+mysqlconnector://{username}:{password}@{host}/{database}'\n",
    "engine = create_engine(engine_url)\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "def insert_and_fetch():\n",
    "    session = Session()\n",
    "    try:\n",
    "        # Measure Insert Time\n",
    "        start_time_insert = time.time()\n",
    "        engine.raw_connection().rollback()  # Explicitly Rollback\n",
    "        df.to_sql(name=table_name, con=engine, index=False, if_exists='replace')\n",
    "        session.commit()\n",
    "        insert_time = time.time() - start_time_insert\n",
    "\n",
    "        # Measure Fetch Time\n",
    "        start_time_fetch = time.time()\n",
    "        connection = mysql.connector.connect(host=host, user=username, password=password, database=database)\n",
    "        cursor = connection.cursor(dictionary=True)\n",
    "        cursor.execute(f\"SELECT * FROM {table_name} where recordid='f30f24bf-f951-4122-99bf-b5d389b896eb';\") #Lets retrieve the third row from the df dataframe having recordId f30f24bf-f951-4122-99bf-b5d389b896eb\n",
    "        rows = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        fetch_time = time.time() - start_time_fetch\n",
    "\n",
    "        # Return Insert Time, Fetch Time, and Total Time\n",
    "        return insert_time, fetch_time, insert_time + fetch_time\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        session.rollback()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "# Run the function and print the results\n",
    "insert_time, fetch_time, total_time = insert_and_fetch()\n",
    "print(f\"Insert Time: {insert_time} seconds\")\n",
    "print(f\"Fetch Time: {fetch_time} seconds\")\n",
    "print(f\"Total Execution Time: {total_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c80d0",
   "metadata": {},
   "source": [
    "# AWS Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77c87dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert Time: 1.014460802078247 seconds\n",
      "Fetch Time: 0.04340100288391113 seconds\n",
      "Total Execution Time: 1.0578618049621582 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# Database connection details\n",
    "username = 'Your_Redshift_username'\n",
    "password = 'Your_Redshift_password'\n",
    "host = 'Your_Redshift_Host'\n",
    "port = '5439'  # default port for Redshift\n",
    "database = 'Your_redshift_database'\n",
    "table_name = 'Your_redshift_tablename'\n",
    "\n",
    "# Create Engine and Session\n",
    "engine_url = f'redshift+psycopg2://{username}:{password}@{host}:{port}/{database}'\n",
    "engine = create_engine(engine_url)\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "def insert_and_fetch():\n",
    "    session = Session()\n",
    "    try:\n",
    "        # Measure Insert Time\n",
    "        start_time_insert = time.time()\n",
    "        df.to_sql(name=table_name, con=engine, index=False, if_exists='replace', schema='public')\n",
    "        session.commit()\n",
    "        insert_time = time.time() - start_time_insert\n",
    "        \n",
    "        # Measure Fetch Time\n",
    "        start_time_fetch = time.time()\n",
    "        connection = psycopg2.connect(user=username, password=password, host=host, port=port, database=database)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(f\"SELECT * FROM public.{table_name} where recordid='f30f24bf-f951-4122-99bf-b5d389b896eb';\")#Lets retrieve the third row from the df dataframe having recordId f30f24bf-f951-4122-99bf-b5d389b896eb\n",
    "        rows = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        fetch_time = time.time() - start_time_fetch\n",
    "        \n",
    "        # Return Insert Time, Fetch Time, and Total Time\n",
    "        return insert_time, fetch_time, insert_time + fetch_time\n",
    "        \n",
    "    except SQLAlchemyError as e:\n",
    "        print(e)\n",
    "        session.rollback()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "# Run the function and print the results\n",
    "insert_time, fetch_time, total_time = insert_and_fetch()\n",
    "print(f\"Insert Time: {insert_time} seconds\")\n",
    "print(f\"Fetch Time: {fetch_time} seconds\")\n",
    "print(f\"Total Execution Time: {total_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed6207",
   "metadata": {},
   "source": [
    "### As you can see it makes sense to use Sagemaker feature Store for feature storage and retrieval as it is 47% faster compared to RDS and 92% faster compared to Redshift"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
